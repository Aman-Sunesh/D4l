{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris, fetch_openml\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import warnings\n",
    "\n",
    "# Ignore any warnings for clean output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Experiment on the Iris Dataset\n",
    "# -------------------------------\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "# Define the nmin values (as percentages) for the Iris dataset\n",
    "# These values will be converted to fractions for scikit-learnâ€™s min_samples_leaf parameter.\n",
    "iris_nmin_values = [5, 10, 15, 20]\n",
    "\n",
    "# Set up 10-fold cross-validation with shuffling for reproducibility\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results in a list of dictionaries\n",
    "iris_results = []\n",
    "\n",
    "for nmin in iris_nmin_values:\n",
    "    # Convert percentage to fraction.\n",
    "    # scikit-learn will use: ceil(nmin_fraction * n_samples) as the minimum number of samples per leaf.\n",
    "    min_samples_leaf = nmin / 100.0\n",
    "    \n",
    "    # Initialize the Decision Tree classifier with the early stopping parameter.\n",
    "    clf = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf, random_state=42)\n",
    "    \n",
    "    # Perform 10-fold cross-validation\n",
    "    scores = cross_val_score(clf, X_iris, y_iris, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    # Append the mean and standard deviation of the accuracy scores\n",
    "    iris_results.append({\n",
    "        'nmin (%)': nmin,\n",
    "        'Mean Accuracy': np.mean(scores),\n",
    "        'Std Accuracy': np.std(scores)\n",
    "    })\n",
    "\n",
    "# Convert the results into a DataFrame for a neat table\n",
    "iris_results_df = pd.DataFrame(iris_results)\n",
    "print(\"Iris Dataset Results:\")\n",
    "print(iris_results_df)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Experiment on the Spambase Dataset\n",
    "# -------------------------------\n",
    "\n",
    "# Load the Spambase dataset from OpenML.\n",
    "# Note: The 'spambase' dataset is available on OpenML. If this fails, ensure you have an internet connection.\n",
    "spambase = fetch_openml('spambase', version=1, as_frame=True)\n",
    "X_spambase = spambase.data\n",
    "y_spambase = spambase.target\n",
    "\n",
    "# Convert the target to integer labels (the target might be loaded as strings)\n",
    "y_spambase = y_spambase.astype(int)\n",
    "\n",
    "# Define the nmin values (as percentages) for the Spambase dataset\n",
    "spambase_nmin_values = [5, 10, 15, 20, 25]\n",
    "\n",
    "spambase_results = []\n",
    "\n",
    "for nmin in spambase_nmin_values:\n",
    "    min_samples_leaf = nmin / 100.0\n",
    "    clf = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf, random_state=42)\n",
    "    scores = cross_val_score(clf, X_spambase, y_spambase, cv=cv, scoring='accuracy')\n",
    "    spambase_results.append({\n",
    "        'nmin (%)': nmin,\n",
    "        'Mean Accuracy': np.mean(scores),\n",
    "        'Std Accuracy': np.std(scores)\n",
    "    })\n",
    "\n",
    "spambase_results_df = pd.DataFrame(spambase_results)\n",
    "print(\"\\nSpambase Dataset Results:\")\n",
    "print(spambase_results_df)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
